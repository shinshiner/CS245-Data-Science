\documentclass[12pt,a4paper]{article}
\usepackage{ctex}
\usepackage{amsmath,amscd,amsbsy,amssymb,latexsym,url,bm,amsthm}
\usepackage{epsfig,graphicx,subfigure}
\usepackage{enumitem,balance}
\usepackage{wrapfig}
\usepackage{mathrsfs, euscript}
\usepackage[usenames]{xcolor}
\usepackage{hyperref}
\usepackage[vlined,ruled,commentsnumbered,linesnumbered]{algorithm2e}
\usepackage{float}
\usepackage{array}
\usepackage{diagbox}
\usepackage{color}
\usepackage{indentfirst}
\usepackage{fancyhdr}
\usepackage{gensymb}
\usepackage{geometry}
\usepackage{setspace}
\usepackage{aurical}
\usepackage{times}
\usepackage{caption}
\usepackage{fontspec}
\usepackage{booktabs}
\setmainfont{Times New Roman}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{exercise}{Exercise}[section]
\newtheorem*{solution}{Solution}
\theoremstyle{definition}


\renewcommand{\thefootnote}{\fnsymbol{footnote}}

\newcommand{\postscript}[2]
 {\setlength{\epsfxsize}{#2\hsize}
  \centerline{\epsfbox{#1}}}

\renewcommand{\baselinestretch}{1.0}

\setlength{\oddsidemargin}{-0.365in}
\setlength{\evensidemargin}{-0.365in}
\setlength{\topmargin}{-0.3in}
\setlength{\headheight}{0in}
\setlength{\headsep}{0in}
\setlength{\textheight}{10.1in}
\setlength{\textwidth}{7in}
\makeatletter \renewenvironment{proof}[1][Proof] {\par\pushQED{\qed}\normalfont\topsep6\p@\@plus6\p@\relax\trivlist\item[\hskip\labelsep\bfseries#1\@addpunct{.}]\ignorespaces}{\popQED\endtrivlist\@endpefalse} \makeatother
\makeatletter
\renewenvironment{solution}[1][Solution] {\par\pushQED{\qed}\normalfont\topsep6\p@\@plus6\p@\relax\trivlist\item[\hskip\labelsep\bfseries#1\@addpunct{.}]\ignorespaces}{\popQED\endtrivlist\@endpefalse} \makeatother



\begin{document}
\noindent
%==========================================================
\noindent\framebox[\linewidth]{\shortstack[c]{
\Large{\textbf{Report on}}\vspace{1mm}\\ 
\Large{\emph{Visualization and exploration of Adult Dataset}}\vspace{1mm}\\
CS245, Data Science Foundation, Chaojun Lu, Autumn 2017 \vspace{1mm} \\
叶泽林 515030910468}}
\vspace{-1.5\baselineskip}
\section{Introduction} % or Problem Description ?

\vspace{-1\baselineskip}
\section{Approaches~\cite{levine2016learning}}
	In sentiment analysis with lexicon-based polarity identification, the orientations of some opinion words might heavily depend on its context. For instance, consider the word \emph{long}:
\begin{itemize}
	\item The battery life is \emph{long}.
	\item The time taken to focus is \emph{long}.
\end{itemize}

	Opinion word \emph{long} for battery life is positive, while \emph{long} for time to focus is negative. This problem is inevitable when using lexicon-based polarity identification, which ignores the context information.

\section{Experiments}


\section{Conclusion}
\begin{enumerate}
	\item Apply the regular lexicon-based polarity identification method on the corpus and filter the adjectives with ambiguous meanings. The remaining ones are treated as absolute ground truth in later training.
	\item Redefine a lexicon to be a word pair in the form of \emph{<object, adjective>},
and apply the revised lexicon-based polarity identification method on it, where
\begin{itemize}
	\item The polarity of positive words: +1, negative word: -1, neutral words: 0.
	\item The words classified by the regular lexicon-based polarity identification method in step 1, and the labeled lexicons in the seed dataset serve as ground truth when training. 
	\item When aggregating opinions, the equation
	\begin{equation}
		score(f_i, s) = \sum_{op_j \in s} \frac{op_{j}.so}{d(op_j, f_i)},
	\end{equation}
	where $op_j$ is an opinion word (either a ground truth or a induced lexicon) in $s$, and $d(op_j, f_i)$ is the distance between the closest words in $op_j$ and $f_i$. $op_{j}.so$ is the orientation or the opinion score of $op_j$. 
\end{itemize}
	\item To make the model more accurate and robust, we further take the context and conjunctions(and, but, however ...) into consideration in long comments, which form links between sentences in each comment. Especially, the same word can appear in different sentences(e.g. ``The battery life is long, but the time taken to focus is long''). Therefore, we can add the sentimental scores of nearby sentences with some weights to the target sentence factored by the conjunctive adverb. A Na\''{i}ve design is that, if there are $n$ conjunctive adverbs(e.g. \emph{but}, \emph{however}), $op_j$ will be multiplied by a adjusting factor ${(-1)}^{n}$. A hand-engineered algorithm could possibly solve this problem, but it would be better to tackle the task by training a neural network.
	\item After training, for each word we receive a score $\in [-1, 1]$, and some thresholds should be defined correspondingly to classify them into three classes.
\end{enumerate}

\section{Acknowledgement}

\renewcommand{\refname}{References}
\bibliographystyle{ieeetr}
\bibliography{bio}
%========================================================================
\end{document}